# src/ollama_manager.py
import requests
import logging
import json
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)

class OllamaManager:
    """GÃ¨re les modÃ¨les via Ollama"""
    
    def __init__(self, model: str = "mistral", base_url: str = "http://localhost:11434"):
        self.model = model
        self.base_url = base_url
        self.is_initialized = False
        self._initialize()
    
    def _initialize(self):
        """VÃ©rifie qu'Ollama fonctionne"""
        try:
            # Test de connexion
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [model['name'] for model in models]
                
                if self.model in model_names or any(self.model in name for name in model_names):
                    self.is_initialized = True
                    logger.info(f"âœ… Ollama initialisÃ© - ModÃ¨le: {self.model}")
                else:
                    logger.error(f"âŒ ModÃ¨le {self.model} non trouvÃ©. ModÃ¨les disponibles: {model_names}")
            else:
                logger.error(f"âŒ Ollama non accessible: {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            logger.error("âŒ Ollama non dÃ©marrÃ©. Lancez: ollama serve")
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation Ollama: {e}")
    
    def generate_response(self, prompt: str) -> str:
        """GÃ©nÃ¨re une rÃ©ponse via Ollama"""
        if not self.is_initialized:
            return "âŒ Ollama non initialisÃ©"
        
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "num_predict": 1024
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            
            result = response.json()
            return result.get('response', '').strip()
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration Ollama: {e}")
            return f"âŒ Erreur: {str(e)}"
    
    def chat_completion(self, messages: list) -> str:
        """Version chat (plus naturelle)"""
        if not self.is_initialized:
            return "âŒ Ollama non initialisÃ©"
        
        try:
            payload = {
                "model": self.model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            
            result = response.json()
            return result['message']['content'].strip()
            
        except Exception as e:
            logger.error(f"âŒ Erreur chat Ollama: {e}")
            return self.generate_response(messages[-1]['content'])  # Fallback
    
    def create_technical_prompt(self, context: str, question: str) -> str:
        """Prompt optimisÃ© pour Ollama"""
        return f"""En tant qu'assistant technique expert, analyse le contexte documentaire suivant et rÃ©ponds Ã  la question.

CONTEXTE DOCUMENTAIRE:
{context}

QUESTION:
{question}

INSTRUCTIONS:
- RÃ©ponds en franÃ§ais de maniÃ¨re structurÃ©e et technique
- Utilise UNIQUEMENT les informations du contexte fourni
- Si l'information n'est pas dans le contexte, indique-le clairement
- Sois prÃ©cis et cite les parties pertinentes du document
- Ã‰vite les rÃ©pÃ©titions et les informations gÃ©nÃ©riques

RÃ‰PONSE TECHNIQUE:"""
    
    def get_model_info(self) -> dict:
        """Retourne les informations du modÃ¨le"""
        return {
            "model": self.model,
            "device": "ğŸ’» Ollama",
            "initialized": self.is_initialized,
            "type": "ollama"
        }
    
    def test_generation(self) -> str:
        """Teste la gÃ©nÃ©ration"""
        if not self.is_initialized:
            return "âŒ Ollama non initialisÃ©"
        
        try:
            response = self.generate_response("Explique l'IA en une phrase.")
            return f"âœ… Ollama ({self.model}): {response[:80]}..."
        except Exception as e:
            return f"âŒ Test Ã©chouÃ©: {e}"