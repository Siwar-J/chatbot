# src/embedding_manager.py
import logging
import torch
from sentence_transformers import SentenceTransformer
from typing import List, Optional
import numpy as np

logger = logging.getLogger(__name__)

class AdvancedEmbeddingManager:
    """Gestionnaire avanc√© pour les embeddings"""
    
    def __init__(self, model_name: str = "intfloat/multilingual-e5-large"):
        self.model_name = model_name
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self._initialize_model()
    
    def _initialize_model(self):
        """Initialise le mod√®le d'embedding avec optimisation"""
        try:
            logger.info(f"üöÄ Chargement du mod√®le d'embedding: {self.model_name}")
            
            # Mod√®les recommand√©s par ordre de performance :
            recommended_models = [
                "intfloat/multilingual-e5-large",      # Excellent pour le multilingue
                "sentence-transformers/all-mpnet-base-v2",  # Tr√®s bon pour l'anglais
                "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
                "dangvantuan/sentence-camembert-large",  # Sp√©cialis√© fran√ßais
            ]
            
            # Essayer les mod√®les dans l'ordre jusqu'√† ce qu'un fonctionne
            for model in [self.model_name] + recommended_models:
                try:
                    self.model = SentenceTransformer(
                        model,
                        device=self.device,
                        trust_remote_code=True
                    )
                    
                    # Test du mod√®le
                    test_embedding = self.model.encode(["test"])
                    if test_embedding is not None and len(test_embedding) > 0:
                        logger.info(f"‚úÖ Mod√®le charg√©: {model} sur {self.device}")
                        self.model_name = model
                        break
                        
                except Exception as e:
                    logger.warning(f"‚ùå √âchec chargement {model}: {e}")
                    continue
            
            if self.model is None:
                raise Exception("Aucun mod√®le d'embedding n'a pu √™tre charg√©")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation embedding: {e}")
            raise
    
    def encode_documents(self, documents: List[str], batch_size: int = 32) -> np.ndarray:
        """Encode les documents avec optimisation"""
        try:
            logger.info(f"üî§ Encodage de {len(documents)} documents...")
            
            # Pr√©paration des textes
            processed_texts = [self._preprocess_text(doc) for doc in documents]
            
            # Encodage par batch pour optimiser la m√©moire
            embeddings = self.model.encode(
                processed_texts,
                batch_size=batch_size,
                show_progress_bar=True,
                convert_to_tensor=True,
                normalize_embeddings=True  # Important pour la similarit√© cosinus
            )
            
            logger.info(f"‚úÖ Embeddings g√©n√©r√©s: {embeddings.shape}")
            return embeddings.cpu().numpy()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur encodage: {e}")
            raise
    
    def _preprocess_text(self, text: str) -> str:
        """Pr√©traitement avanc√© du texte"""
        if not text:
            return ""
        
        # Nettoyage de base
        text = ' '.join(text.split())
        
        # Ajout d'instructions pour les mod√®les E5
        if "e5" in self.model_name.lower():
            text = f"passage: {text}"
        
        return text
    
    def encode_query(self, query: str) -> np.ndarray:
        """Encode une requ√™te avec formatage sp√©cifique"""
        try:
            # Formatage sp√©cial pour les requ√™tes avec les mod√®les E5
            if "e5" in self.model_name.lower():
                query = f"query: {query}"
            
            embedding = self.model.encode(
                [query],
                convert_to_tensor=True,
                normalize_embeddings=True
            )
            
            return embedding.cpu().numpy()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur encodage requ√™te: {e}")
            raise

# Configuration des embeddings
EMBEDDING_CONFIGS = {
    "multilingual": "intfloat/multilingual-e5-large",
    "french": "dangvantuan/sentence-camembert-large", 
    "english": "sentence-transformers/all-mpnet-base-v2",
    "balanced": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
}